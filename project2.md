<img src="https://r2cdn.perplexity.ai/pplx-full-logo-primary-dark%402x.png" style="height:64px;margin-right:32px"/>

# ببین فرمول ها قابل کپی نیستن. میخوام توی یک فایل حالا نمی دونم چه فرمتی txt یا md توی vs code ذخیره کنم توی فولدر پروژم. پس اگر راهی هست بهم بگو چطوری کپی کنم و فرمت فایل چی باشه و اگر نیست که فقط ورژن متنی فرمول هارو برام بنویس.

مجدد بفرست

بهترین راه این است که متن و فرمول‌ها را در یک فایل Markdown با پسوند .md ذخیره شود تا همه فرمول‌ها به‌صورت LaTeX قابل کپی و ویرایش در VS Code باشند؛ نسخه‌ی متنیِ همه فرمول‌های مقاله در ادامه آمده است تا مستقیم کپی و در فایل پروژه قرار داده شود. اگر نیاز به کپی دقیق از منبع دارید، دریافت «Source» از صفحه مقاله در arXiv و باز کردن فایل .tex نیز راه مطمئنی برای دسترسی به فرمول‌های خام است.[^1][^2][^3]

## فرمت فایل پیشنهادی

- فرمت پیشنهادی: فایل .md با فرمول‌های LaTeX داخل نشانه‌گذاری‌های \$ \$ برای درون‌خط و \$ \$ برای بلوکی؛ این روش در VS Code به‌خوبی قابل ویرایش و کپی است و نیاز به ابزار خاصی ندارد.[^3][^1]
- گزینه جایگزین: اگر نیاز به رندر حرفه‌ای یا ارجاع‌دهی خودکار دارید، می‌توان یک فایل .tex ساخت و همان فرمول‌ها را در سند LaTeX قرار داد؛ اما برای تمرین/متن قابل کپی، .md ساده‌تر است.[^1][^3]
- نحوه ذخیره: یک فایل README.md یا formulas.md در فولدر پروژه بسازید، بخش «متن فرمول‌ها (قابل کپی)» زیر را عیناً در آن قرار دهید و ذخیره کنید؛ در صورت نیاز به رندر، افزونه‌های پیش‌نمایش Markdown در VS Code قابل استفاده‌اند، ولی برای کپی کردن ضرورتی ندارند.[^3][^1]


## روش‌های کپی دقیق از arXiv

- در صفحه مقاله در arXiv معمولاً گزینه «Other formats» وجود دارد که شامل «Source» نیز هست؛ با دریافت Source (فشرده)، فایل .tex رسمی مقاله را خواهید داشت و می‌توانید فرمول‌ها را دقیق و بدون به‌هم‌ریختگی کپی کنید.[^2][^3]
- برای برخی مقالات، نمای HTML آزمایشی هم ارائه می‌شود که کپی از آن، مشکلات لیگیچر/کاراکترهای PDF را ندارد؛ اگر برای این مقاله فعال بود، می‌توان متن و فرمول‌ها را از HTML برداشت و در فایل .md چسباند.[^4][^3]


## متن فرمول‌ها (قابل کپی)

در ادامه، همه فرمول‌های شماره‌گذاری‌شده و تعریف‌های کلیدی مقاله به‌ترتیب و با نگارش LaTeX آورده شده‌اند تا مستقیماً در فایل .md یا .tex کپی شوند.[^1][^3]

- معادله (1) — سیگنال تک‌تن OFDM کاربر k در SG شماره m و نماد i.[^3][^1]

$$
s_{k,m,i}[n] \;=\; \beta_k \, e^{j\,2\pi\,\phi_k[m]\,\frac{n}{N}}
$$

- معادله (2) — پاسخ کانال چندمسیره کاربر k به‌صورت ضربه‌ای در حوزه زمان.[^1][^3]

$$
h_k(\tau) \;=\; \sum_{p=0}^{P_k-1} a_{k,p}\,\delta(\tau - \tau_{k,p})
$$

- معادله (3) — تعریف زمانِ رسیدن سیگنال (ToA) به‌صورت کمینه تأخیر مسیرها.[^3][^1]

$$
D_k \;:=\; \min_{p}\,\tau_{k,p}
$$

- معادله (4) — سیگنال دریافتی پس از نمونه‌برداری در BS با درنظرگرفتن CFO و AWGN.[^1][^3]

$$
y_{m,i}[n] \;=\; \sum_{k=0}^{K-1} \sum_{\ell=-\infty}^{\infty} A_k \, h_{k,\ell} \, s_{k,m,i}[n-\ell] \, e^{j\,2\pi\, f_{\text{off},k}(n-\ell)} \;+\; w_{m,i}[n]
$$

- معادلات (5)–(6) — ضرایب کانال گسسته با شکل‌دهی پالسی sinc و تفسیر حوزه فرکانس.[^3][^1]

$$
h_{k,\ell} \;=\; \sum_{p=0}^{P_k-1} a_{k,p}\,\mathrm{sinc}\!\big(\ell - W\,\tau_{k,p}\big) \;=\; \mathcal{F}^{-1}\!\left\{\mathrm{rect}(f)\, H_k(f)\right\}(\ell)
$$

که در آن $W = N\,\Delta f$ پهنای باند، $\mathcal{F}^{-1}$ تبدیل فوریه معکوس و $\mathrm{rect}(f)$ تابع مستطیلی در باند است.[^1][^3]

- معادله (7) — پاسخ فرکانسی کانال مبتنی بر مجموع مسیرها.[^3][^1]

$$
H_k(f) \;=\; \sum_{p=0}^{P_k-1} a_{k,p}\, e^{-j\,2\pi\, \tau_{k,p}\, W\, f}
$$

- تعریف شبکه منبع (Resource Grid) و نمونه RG: پس از حذف CP و DFT، ماتریس $Y\in\mathbb{C}^{N\times 5S}$ به‌دست می‌آید که S تعداد SG در پیش‌نواختار (پری‌امبل) است و نمایه زمان‌نماد برای SGِ m و نماد i برابر $5m+i$ می‌باشد. همچنین $N_{m,i} := m\,N_{\text{SG}} + i\,N$ بوده و $N_{\text{SG}}$ تعداد نمونه در هر SG است.[^1][^3]
- معادله (8) — مؤلفه روی زیرحامل فعال $\phi_k[m]$ با جمع ICI ناشی از CFO بقیه کاربران و نویز.[^3][^1]

$$
\begin{aligned}
Y[\phi_k[m],\, 5m+i] \;=&\; A_k\, H_k\!\left(\frac{\phi_k[m]}{N}\right)\,\beta_k \cdot \frac{1}{N}\! \sum_{n=N_{m,i}}^{N_{m,i}+N-1} e^{j\,2\pi\, f_{\text{off},k}\, n} \\
&+ \sum_{k'\neq k} A_{k'}\, H_{k'}\!\left(\frac{\phi_k[m]}{N}\right)\,\beta_{k'} \cdot \frac{1}{N}\! \sum_{n=N_{m,i}}^{N_{m,i}+N-1} e^{j\,2\pi\,\left(\frac{\phi_{k'}[m]-\phi_k[m]}{N} + f_{\text{off},k'}\right) n} \\
&+ W_{k,m,i}[\phi_k[m],\, 5m+i]
\end{aligned}
$$

- معادله (9) — تابع زیان برآورد فعالیت کاربران (BCE).[^1][^3]

$$
L_1 \;:=\; - \sum_{k=0}^{K-1} \mathbb{E}\!\left[ \ln\big(\widehat{\Pr}(A_k \mid \bar{Y})\big) \right]
$$

- معادله (10) — برآورد مونت‌کارلو برای $L_1$ با اندازه بچ $B$ و شاخص $[b]$.[^3][^1]

$$
\begin{aligned}
L_1 \;\approx\; -\frac{1}{B} \sum_{b=0}^{B-1} \sum_{k=0}^{K-1} \Big(&A_k^{[b]}\, \ln\big(\widehat{\Pr}(A_k^{[b]} \mid \bar{Y}^{[b]})\big) \\
&+ (1-A_k^{[b]})\, \ln\big(1 - \widehat{\Pr}(A_k^{[b]} \mid \bar{Y}^{[b]})\big) \Big)
\end{aligned}
$$

- معادله (11) — تابع زیان وزن‌دار MSE برای ToA و CFO با وزن‌ SNR و فعالیت $A_k$.[^1][^3]

$$
L_2 \;:=\; \sum_{k=0}^{K-1} \mathbb{E}\!\left[A_k\,\mathrm{SNR}_k \,\big(D_k - \widehat{D}_k\big)^2\right] \;+\; \sum_{k=0}^{K-1} \mathbb{E}\!\left[A_k\,\mathrm{SNR}_k \,\big(f_{\text{off},k} - \hat f_{\text{off},k}\big)^2\right]
$$

- معادله (12) — تعریف SNR متوسط کاربر k روی الگوی جهش فرکانسی.[^3][^1]

$$
\mathrm{SNR}_k \;:=\; \frac{\beta_k}{\sigma^2}\,\frac{1}{S}\,\sum_{m=0}^{S-1} \left|\, H_k\!\left(\frac{\phi_k[m]}{N}\right) \right|^2
$$

- معادله (13) — برآورد تجربی $L_2$ روی بچ.[^1][^3]

$$
\begin{aligned}
L_2 \;\approx\;& \frac{1}{B} \sum_{k=0}^{K-1} \sum_{b=0}^{B-1} A_k^{[b]}\,\mathrm{SNR}_k^{[b]}\, \big(D_k^{[b]} - \widehat{D}_k^{[b]}\big)^2 \\
&+ \frac{1}{B} \sum_{k=0}^{K-1} \sum_{b=0}^{B-1} A_k^{[b]}\,\mathrm{SNR}_k^{[b]}\, \big(f_{\text{off},k}^{[b]} - \hat f_{\text{off},k}^{[b]}\big)^2
\end{aligned}
$$

- معادله (14) — زیان کل برای آموزش مشترک دو سرِ شبکه.[^3][^1]

$$
L \;:=\; L_1 + L_2
$$

- سایر نمادها/تعاریف کلیدی برای کپی: $K$ بیشینه تعداد الگوهای جهش/کاربران بدون تصادم، $\Delta f = 3.75\,\text{kHz}$، تعداد زیرحامل‌های NPRACH برابر 48، یک تکرار پری‌امبل یعنی $S=4$، و شاخص‌گذاری RG با بعد $N\times 5S$ پس از DFT هر SG است. همچنین \$\$\bar{Y}\in\mathbb{R[^1][^3]
<span style="display:none">[^10][^11][^12][^5][^6][^7][^8][^9]</span>

<div style="text-align: center">⁂</div>

[^1]: 2205.10805v2.pdf

[^2]: http://arxiv.org/list/cs/2022-05?skip=2725\&show=2000

[^3]: https://arxiv.org/pdf/2205.10805.pdf

[^4]: https://arxiv.org/abs/2404.17632

[^5]: https://ui.adsabs.harvard.edu/abs/2022arXiv220510805A/abstract

[^6]: https://arxiv.org/abs/2203.10558

[^7]: https://arxiv.org/abs/2502.17225

[^8]: https://github.com/NVlabs/nprach_synch

[^9]: https://news.ycombinator.com/item?id=38724665

[^10]: https://jglobal.jst.go.jp/detail?JGLOBAL_ID=202202216300306710

[^11]: https://www.reddit.com/r/MachineLearning/comments/1ak5u1q/d_anyone_else_sad_that_arxivvanity_is_down/

[^12]: https://github.com/NVlabs/nprach_synch/activity

