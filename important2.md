<img src="https://r2cdn.perplexity.ai/pplx-full-logo-primary-dark%402x.png" style="height:64px;margin-right:32px"/>

# این موارد زیر رو مجدد بررسی کن ببین پیدا میکنی ابهات من رو و دقیق ارسال کن. هر موردی که یافت نشد بنویس جلوش :

اندازه DFT و پهنای باند مؤثر:
مقدار دقیق N (اندازه FFT) برای ساخت RG. در متن اشاره‌ای غیرمستقیم به N=256 برای baseline دیده شده، اما باید صریح تثبیت شود که همین N برای ورودی شبکه نیز به‌کار می‌رود. اگر N=256 باشد، W=N·Δf=960 kHz و لازمه‌اش مشخصات دسیماسیون/فیلتر ضد‌روبش از 50 MHz به W است.
نگاشت دقیق 48 زیرحامل NPRACH به ایندکس‌های DFT (offset از DC، پیوستگی/فاصله‌گذاری، ناحیه اشغال‌شده در 256 بین).
طول‌های عددی در نمونه:
طول CP و SG به واحد نمونه در نرخ W (نه fs=50 MHz). نیاز است: N_SG (نمونه‌های هر SG بعد از دسیماسیون)، N (طول DFT هر نماد)، و نسبت N_CP به N.
تولید الگوی جهش:
نحوه تولید توالی φ_k[m] (منطبق بر جدول/قاعده 3GPP دقیق یا ساده‌سازی مقاله). لازم برای ساخت Y[φ_k[m], 5m+i] و بعد از میانگین‌گیری.
دقیق‌سازی سناریوی چندکاربری:
تعداد الگوهای فعال همزمان در هر نمونه آموزش/ارزیابی. «بدون تصادم» در ارزیابی به معنی حداکثر یک کاربر فعال است یا صرفاً φ_k‌ها ناهمپوشان‌اند؟ P(A_k) چگونه اعمال می‌شود (Bernoulli با p ثابت یا فرآیند دیگر). مقدار p برای شکل‌های 3a–3c (در متن شما p≈0.5 ذکر شده) باید تثبیت شود.
پارامترهای کانال UMi:
تعداد مسیرها/مدل تأخیری و توان‌ها، انتخاب LOS/NLOS، کِی‌فاکتور (اگر LOS)، توزیع دقیق large‑scale (pathloss/shadowing) و اینکه SNRk چگونه از معادله (12) دقیقاً محاسبه و نویز σ² تنظیم می‌شود.
تعریف‌های نرمال‌سازی در ویژگی:
فرمول نرمال‌سازی توالی‌ها (محور، مقیاس، ε برای پایداری عددی) و فرمول کانال سوم: log-power دقیقاً به‌صورت 10·log10(mean(|·|²)+ε) یا گونه دیگر.
خروجی/واحدهای اهداف رگرسیونی:
واحد هدف CFO در آموزش (ppm یا Hz) و فرمول دقیق هدف (و در صورت نیاز نرمال‌سازی هدف). واحد هدف ToA (μs یا نمونه) و دامنه مجاز آن.
تعریف RMSE «نرمال‌شده» در شکل‌ها:
ToA RMSE نرمال‌شده بر چه پایه‌ای (مثلاً نسبت به طول CP) و CFO RMSE نرمال‌شده نسبت به چه مرجعی (مثلاً ppm ماکزیمم یا Δf).
جزئیات معماری که برای پیاده‌سازی لازم است:
تعداد بلوک‌های ResNet، ابعاد کانال‌ها در هر بلوک، kernel/stride/padding دقیق، ترتیب LayerNorm و محور آن، وجود/عدم وجود pooling، dropout، weight decay، clip گرادیان.
تنظیمات آموزش:
تعداد epoch، schedule (step/cosine)، معیار توقف زودهنگام، اندازه دیتاست‌های train/val/test و توزیع SNR/CFO/ToA در هر یک، seedهای تصادفی و تعداد نمونه‌های ارزیابی در هر نقطه SNR/CFO جهت هموار بودن منحنی‌ها.
baseline مرجع برای آشکارسازی:
مقادیر هدف P_FA در متن شما به‌صورت 99% و 99.9% آمده که از منظر آشکارسازی غیرمعمول است (انتظار می‌رود 1% و 0.1%). نیاز به تثبیت این ارقام و روش محاسبه/کالیبراسیون آستانه γ بر حسب توزیع نویز و پاسخ مرجع.
جزئیات برچسب‌گذاری در حضور چند کاربر:
نحوه محاسبه خروجی‌های رگرسیون برای kهای غیرفعال (نادیده‌گرفتن با Ak=0 در زیان انجام می‌شود، اما مقدار هدف چه می‌شود) و نحوه جمع‌بندی زیان روی K سر مشترک.

خلاصه: بخشی از جزئیات دقیق در مقاله موجود است و بخشی تصریح نشده یا فقط اشارهٔ غیرمستقیم دارد؛ در ادامه هر مورد، دقیقاً بر اساس متن مقاله ارائه شده و هر آنچه ذکر نشده، صراحتاً «یافت نشد» علامت‌گذاری شده است.[^1][^2]

## اندازه DFT و پهنای باند

- اندازه DFT برای baseline: FFT سایز 256 صراحتاً برای الگوریتم مرجع گزارش شده است.[^2][^1]
- اندازه DFT برای ساخت RG ورودی شبکه: مقدار عددی N برای شبکه صریحاً ذکر نشده و فقط به N به‌عنوان «تعداد زیرحامل‌های پردازش‌شده در BS» اشاره شده است؛ بنابراین «یافت نشد» که همان 256 برای ورودی شبکه به‌کار رفته باشد.[^1][^2]
- پهنای باند مؤثر W: تعریف کلی $W=N\Delta f$ آمده است، اما چون N برای شبکه تصریح نشده، عدد دقیق W برای مسیر پردازش شبکه «یافت نشد»؛ تنها $\Delta f=3.75\,\text{kHz}$ و ۴۸ زیرحامل NPRACH مشخص است.[^2][^1]
- دسیماسیون/فیلتر از 50 MHz به W: دربارهٔ زنجیرهٔ دسیماسیون یا فیلتر ضدروبش هیچ جزئیاتی گزارش نشده است؛ «یافت نشد».[^1][^2]


## نگاشت ۴۸ زیرحامل به ایندکس DFT

- نگاشت دقیق اندیس‌ها نسبت به DC و فاصله‌گذاری در 256 بین: فقط فرم کلی $Y[\phi_k[m],\,5m+i]$ و «متعامد بودن الگوها» آمده و نگاشت عددیِ ناحیه اشغال‌شده حول DC یا offset از DC «یافت نشد».[^2][^1]


## طول‌های عددی در نمونه

- طول CP: $66.7\,\mu s$ (برابر بازه نمونه‌گیری ToA) صراحتاً ذکر شده است.[^1][^2]
- طول SG و مؤلفه‌ها به «نمونه»: فرمول $N_{m,i}=mN_{\text{SG}}+iN$ آمده، اما مقادیر عددی $N_{\text{SG}}$، $N$ و نسبت $N_{\text{CP}}/N$ برای سناریوی شبکه «یافت نشد»؛ فقط ذکر شده هر SG پنج نماد OFDM را با یک CP مشترک شامل می‌شود.[^2][^1]


## تولید الگوی جهش

- نحوه تولید $\phi_k[m]$: «طبق مشخصات 3GPP» و جهش شبه‌تصادفی بین SGها بیان شده است، اما جدول/قاعدهٔ صریح الگو در متن مقاله «یافت نشد»؛ فقط گفته شده ۴۸ الگوی متعامد وجود دارد و کاربران هم‌زمان باید الگوی متفاوت انتخاب کنند.[^1][^2]


## سناریوی چندکاربری

- حداکثر کاربران/الگوها: $K=48$ بدون تصادم، یعنی برای کاربران فعالِ هم‌زمان $\phi_k[m]\neq \phi_{k'}[m]$ است؛ این به‌معنای «عدم همپوشانی الگوها» است و نه لزوماً «یک کاربر».[^2][^1]
- احتمال فعالیت P(Ak): در آموزش برای هر batch به‌طور مستقل و یکنواخت از $(0,1)$ کشیده می‌شود؛ در ارزیابیِ شکل‌های 3a تا 3c مقدار $P(A_k)=0.5$ تنظیم شده است؛ برای شکل 3e متن صرفاً «میانگین‌گیری روی همه تحقق‌های کانال» را ذکر می‌کند و مقدار p را تصریح نمی‌کند.[^1][^2]


## پارامترهای کانال UMi

- مدل: 3GPP UMi با کانال چندمسیرهٔ «زمان‌نامتغیر» در بازه پری‌امبل، به‌همراه AWGN و CFO مستقل برای هر UE به‌کار رفته است.[^2][^1]
- جزئیات مسیر/توان/تاخیر: فرم ریاضی کانال و taps مبتنی بر sinc و $H_k(f)$ ارائه شده ولی تعداد مسیرها/پروفایل تأخیری/توان‌ها، انتخاب LOS/NLOS و K‑factor صراحتاً «یافت نشد» و به استاندارد 38.901 ارجاع غیرمستقیم دارد.[^1][^2]
- بزرگ‌مقیاس و SNR: «ریزش تصادفی کاربران با پارامترهای large‑scale تصادفی» ذکر شده و $\mathrm{SNR}_k$ طبق معادله (12) تعریف شده است؛ نحوهٔ تنظیم دقیق $\sigma^2$ و نگاشت به SNR عددی «یافت نشد».[^2][^1]


## نرمال‌سازی ویژگی

- فرایند: ۵ RE هر SG روی هر زیرحامل میانگین می‌شود؛ برای هر الگوی جهش، توالی SGها استخراج و «به‌صورت جداگانه نرمال‌سازی» می‌گردد؛ سپس Re/Im انباشته می‌شود و «توان میانگین دریافتی در مقیاس لگاریتمی» به‌عنوان کانال سوم اضافه می‌شود؛ فرمول دقیق نرمال‌سازی و شکل لاگ‌-توان (مثلاً $10\log_{10}(\cdot)+\epsilon$) و مقدار $\epsilon$ «یافت نشد».[^1][^2]


## خروجی/واحد اهداف رگرسیونی

- CFO: هدف رگرسیون $f_{\text{off},k}$ است که در مدل دریافت «نسبت به نرخ نمونه‌برداری نرمال‌شده» تعریف شده؛ در داده‌سازی CFO به ppm کشیده می‌شود، اما واحد نهاییِ هدفِ آموزشی (ppm یا مقدار نرمال‌شده) صریحاً «یافت نشد»؛ از معادله (4) برمی‌آید که مقدارِ مورد استفاده در زیان همان $f_{\text{off},k}$ نرمال‌شده است.[^2][^1]
- ToA: هدف $D_k$ است؛ ToA در تولید داده از $[0,66.7\,\mu s]$ کشیده می‌شود و در زیان با همان واحد فیزیکی به‌کار می‌رود؛ نرمال‌سازیِ هدف ToA برای آموزش ذکر نشده و «یافت نشد».[^1][^2]


## تعریف RMSE «نرمال‌شده»

- ToA/CFO RMSE: شکل‌ها «Normalized RMSE» را نمایش می‌دهند، اما مبنای نرمال‌سازی (مثلاً نسبت به طول CP یا حداکثر ppm) در متن صریحاً «یافت نشد»؛ تنها محورهای شکل‌ها و برچسب‌ها ارائه شده است.[^2][^1]


## جزئیات معماری لازم برای پیاده‌سازی

- کانولوشن: Separable Conv1D با ۱۲۸ کرنلِ اندازه ۳، padding صفر، و skip‑connection گزارش شده است.[^1][^2]
- سر آشکارساز: MLP با Dense 1024/ReLU، سپس 256/ReLU و خروجی 1/Sigmoid طبق دیاگرام شکل 2 ذکر شده است.[^2][^1]
- سرهای رگرسیون ToA/CFO: MLP با Dense 512/ReLU و خروجی 1/Linear برای هر سر طبق دیاگرام آمده است.[^1][^2]
- تعداد دقیق بلوک‌های ResNet، ابعاد کانال‌ها در هر بلوک، stride/padding هر لایه، ترتیب LayerNorm، وجود Pooling/Dropout/Weight decay/Clip گرادیان: در متن عددگذاری و فهرست کامل «یافت نشد» و صرفاً دیاگرام سطح‌بالا ارائه شده است.[^2][^1]


## تنظیمات آموزش

- بهینه‌ساز/نرخ/بچ: Adam با $10^{-3}$ و batch=64 صریحاً گزارش شده است.[^1][^2]
- تعداد epoch، schedule یادگیری، early stopping، اندازهٔ دقیق train/val/test، توزیع SNR/CFO/ToA در هر کدام، seedهای تصادفی و شمار نمونه‌های ارزیابی در هر نقطهٔ SNR/CFO: همگی در متن مقاله «یافت نشد».[^2][^1]


## baseline مرجع و آستانه

- P_FA هدف: متن می‌گوید «دو مقدار برای آستانه انتخاب شد که متناظر با false alarm probabilities برابر 99.9% و 99% هستند (مطابق )»؛ این عبارت غیرمعمول است اما عیناً همین‌گونه درج شده و روش دقیق کالیبراسیون آستانه $\gamma$ توضیح داده نشده است.[^3][^1][^2]
- سایر جزئیات baseline: FFT سایز 256 استفاده شده است؛ الگوریتم بر اساس آثار  پیاده‌سازی شده ولی گام‌های عملی تعیین $\gamma$ و تبدیل آن به آستانهٔ توان «یافت نشد».[^4][^5][^3][^1][^2]


## برچسب‌گذاری در حضور چندکاربر

- تشخیص فعالیت: زیان $L_1$ با BCE روی برچسب‌های باینری $A_k$ محاسبه می‌شود و برای همهٔ $k$ اعمال می‌گردد.[^1][^2]
- رگرسیون ToA/CFO: زیان $L_2$ فقط با وزن $A_k\,\mathrm{SNR}_k$ محاسبه می‌شود تا کاربران غیرفعال به‌طور مؤثر کنار گذاشته شوند؛ مقدار هدف برای $k$‌های غیرفعال در زیان نقشی ندارد و جمع روی همهٔ $K$ سر با همین وزن‌گذاری انجام می‌شود.[^2][^1]

اگر بخشی از موارد فوق برای پیاده‌سازی لازم است و در متن مقاله «یافت نشد»، بهترین مرجع تکمیلی مخزن پیاده‌سازی نویسندگان است تا مقادیر عملیاتیِ استفاده‌شده در کد مشخص شود، زیرا مقاله عمداً بسیاری از جزئیات مهندسی را خلاصه کرده است.[^1][^2]

<div style="text-align: center">⁂</div>

[^1]: 2205.10805v2.pdf

[^2]: https://arxiv.org/pdf/2205.10805.pdf

[^3]: http://arxiv.org/list/cs/2022-05?skip=2725\&show=2000

[^4]: https://ui.adsabs.harvard.edu/abs/2022arXiv220510805A/abstract

[^5]: http://arxiv.org/list/math/2022-05?skip=2090\&show=250

